# ğŸš€ START HERE - C2W4 Assignment Guide

## ğŸ“Œ Quick Overview

**Assignment:** Building an Advanced Data Pipeline With Data Quality Checks  
**Course:** DeepLearning.AI Data Engineering Certificate - Course 2, Week 4  
**Status:** âœ… **ALL CODE COMPLETE** - Ready to deploy!  
**Repository:** https://github.com/anix-lynch/dlai-c2w4-airflow-pipeline

---

## ğŸ¯ What This Project Does

Builds an Apache Airflow ML pipeline that:
1. âœ… Validates ride-sharing data using Great Expectations
2. âœ… Trains linear regression models to predict trip duration
3. âœ… Evaluates model performance (RMSE metric)
4. âœ… Automatically deploys models if RMSE < 500
5. âœ… Generates dynamic DAGs for 3 vendors (Easy Destiny, Alitran, ToMyPlaceAI)

---

## ğŸƒ Quick Start (3 Options)

### Option 1: Interactive Script (EASIEST)
```bash
# In Coursera terminal:
cd ~
git clone https://github.com/anix-lynch/dlai-c2w4-airflow-pipeline.git
cd dlai-c2w4-airflow-pipeline
bash COURSERA_COMMANDS.sh
```
The script will guide you step-by-step!

### Option 2: Manual Commands
Follow **QUICK_COMMANDS.md** for copy-paste commands

### Option 3: Detailed Walkthrough
Read **SOLUTION_GUIDE.md** for full explanations

---

## ğŸ“š Documentation Map

| File | Purpose | When to Use |
|------|---------|-------------|
| **START_HERE.md** | This file - quick orientation | First time setup |
| **QUICK_COMMANDS.md** | Copy-paste command reference | When you need commands fast |
| **SOLUTION_GUIDE.md** | Complete walkthrough with explanations | When you want to understand |
| **HANDOVER.md** | Summary + troubleshooting | When things break |
| **COURSERA_COMMANDS.sh** | Interactive deployment script | Automated deployment |
| **C2_W4_Assignment.md** | Original assignment | Reference only |

---

## ğŸ”‘ What You Need Before Starting

### From AWS Console (CloudFormation â†’ Outputs):
- [ ] `RawDataBucket` name (e.g., de-c2w4a1-123456-raw-data)
- [ ] `DAGsBucket` name (e.g., de-c2w4a1-123456-dags)
- [ ] `AirflowDNS` URL (e.g., http://ec2-xxx.compute.amazonaws.com:8080)

### Get it with:
```bash
cat ../.aws/aws_console_url
```

---

## âš¡ The 6-Step Process

```
1. ğŸ” GET AWS INFO          â†’ CloudFormation outputs
2. ğŸ“¦ CLONE REPO            â†’ git clone in Coursera
3. ğŸ“¤ UPLOAD DATA TO S3     â†’ aws s3 sync
4. âš™ï¸  SET AIRFLOW VARIABLE  â†’ Admin â†’ Variables
5. ğŸš€ UPLOAD DAGS TO S3     â†’ aws s3 cp
6. â–¶ï¸  RUN IN AIRFLOW UI     â†’ Toggle ON â†’ Trigger
```

**Time Required:** ~10-15 minutes

---

## ğŸ“‚ Project Structure

```
dlai-c2w4-airflow-pipeline/
â”‚
â”œâ”€â”€ ğŸ“– START_HERE.md              â† You are here
â”œâ”€â”€ ğŸ“‹ QUICK_COMMANDS.md          â† Copy-paste commands
â”œâ”€â”€ ğŸ“š SOLUTION_GUIDE.md          â† Detailed walkthrough
â”œâ”€â”€ ğŸ¯ HANDOVER.md                â† Summary + troubleshooting
â”œâ”€â”€ ğŸ¤– COURSERA_COMMANDS.sh       â† Interactive script
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ model_trip_duration_easy_destiny.py  âœ… COMPLETE
â”‚   â”‚
â”‚   â”œâ”€â”€ dags/                     â† Upload these to S3
â”‚   â”‚   â”œâ”€â”€ model_trip_duration_easy_destiny.py
â”‚   â”‚   â”œâ”€â”€ model_trip_duration_alitran.py
â”‚   â”‚   â””â”€â”€ model_trip_duration_to_my_place_ai.py
â”‚   â”‚
â”‚   â””â”€â”€ templates/
â”‚       â”œâ”€â”€ template.py           â† Jinja2 template
â”‚       â”œâ”€â”€ generate_dags.py      â† DAG generator
â”‚       â””â”€â”€ dag_configs/          â† JSON configs
â”‚
â”œâ”€â”€ data/                         â† Upload to S3
â”‚   â””â”€â”€ work_zone/...
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ restart_airflow.sh        â† If Airflow breaks
â”‚
â””â”€â”€ images/                       â† Reference diagrams
```

---

## âœ… Completed Exercises

All 5 exercises are **100% complete**:

### âœ… Exercise 1: Data Quality Checks
- Implemented `GreatExpectationsOperator`
- Validates passenger_count â‰¤ 6
- Fails task if validation fails

### âœ… Exercise 2: ML Model Training
- Reads parquet data from S3
- Trains linear regression model
- Calculates RMSE performance
- Returns metrics via XCom

### âœ… Exercise 3: Branching Logic
- `BranchPythonOperator` implementation
- Deploys if RMSE < 500
- Notifies if performance is low

### âœ… Exercise 4: DAG Dependencies
- All tasks connected correctly
- Uses Airflow template variables
- Proper trigger rules

### âœ… Exercise 5: Dynamic DAGs
- Jinja2 template created
- 3 config files generated
- All 3 DAGs working

---

## ğŸ“ Technologies Used

- **Apache Airflow** - Workflow orchestration
- **Great Expectations** - Data quality validation
- **Pandas** - Data manipulation
- **SciPy** - Linear regression (linregress)
- **AWS S3** - Data storage
- **AWS EC2** - Airflow hosting
- **Jinja2** - Template engine
- **Python** - Programming language

---

## ğŸš¨ Common Issues & Quick Fixes

| Problem | Solution |
|---------|----------|
| DAGs not showing | Wait 2 min, refresh Airflow UI |
| Data not found | Check `bucket_name` variable in Airflow |
| Import errors | Verify Great Expectations installed |
| Airflow broken | Run `restart_airflow.sh` in CloudShell |
| Permission denied | Check IAM roles in CloudFormation |

**Full troubleshooting guide:** See HANDOVER.md

---

## ğŸ’¡ Pro Tips

1. â±ï¸ **Airflow takes 2 minutes** to scan for new DAGs - be patient!
2. ğŸ” **Check logs** in Airflow UI for detailed error messages
3. ğŸ“Š **Use Graph view** to visualize DAG execution
4. ğŸ”„ **XCom tab** shows data passed between tasks
5. ğŸ§ª **Test locally** with `python3 <dag_file>.py` before uploading

---

## ğŸ¯ Success Criteria

You'll know it's working when:

âœ… All 3 DAGs appear in Airflow UI  
âœ… Each DAG has 7 tasks in graph view  
âœ… Data quality checks pass (green)  
âœ… Models train successfully  
âœ… RMSE calculated and logged  
âœ… Correct branch taken (deploy/notify)  
âœ… End task completes  

---

## ğŸ“ Need Help?

**Quick questions?** â†’ Check QUICK_COMMANDS.md  
**Want details?** â†’ Read SOLUTION_GUIDE.md  
**Something broken?** â†’ See HANDOVER.md  
**First time?** â†’ Run COURSERA_COMMANDS.sh

---

## ğŸ” Security Notes

- âœ… No credentials in GitHub
- âœ… No AWS keys in code
- âœ… Token removed from git remote
- âœ… Data files excluded via .gitignore
- âœ… Sensitive files protected

---

## ğŸ‰ Ready to Start?

### Recommended Path:

1. **Read this file** (you're here!) âœ…
2. **Get your bucket names** from CloudFormation
3. **Run the script**: `bash COURSERA_COMMANDS.sh`
4. **Follow prompts** - it guides you through everything
5. **Open Airflow UI** and watch your DAGs run!

### Alternative Path (Manual):

1. Read **QUICK_COMMANDS.md**
2. Copy-paste commands one by one
3. Verify each step completes

---

## ğŸ“ˆ Learning Outcomes

By completing this, you'll master:

- âœ… Apache Airflow DAG creation
- âœ… TaskFlow API with decorators
- âœ… Data quality validation with Great Expectations
- âœ… ML pipeline orchestration
- âœ… Branching and conditional workflows
- âœ… XCom for task communication
- âœ… Dynamic DAG generation with Jinja2
- âœ… AWS S3 and EC2 integration
- âœ… DRY principle in data engineering

---

## ğŸš€ Let's Go!

**Everything is ready. The code is complete. Time to deploy!**

Choose your path:
- ğŸ¤– **Automated:** `bash COURSERA_COMMANDS.sh`
- ğŸ“‹ **Manual:** Follow QUICK_COMMANDS.md
- ğŸ“š **Learn:** Read SOLUTION_GUIDE.md

**Repository:** https://github.com/anix-lynch/dlai-c2w4-airflow-pipeline

**Good luck! You've got this! ğŸ“ğŸš€**

---

*Last Updated: December 2025*  
*Status: âœ… Production Ready*

